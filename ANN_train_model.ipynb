{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b77e3c",
   "metadata": {},
   "source": [
    "This script builds, trains, and evaluates a nueral network surrogate model to predict the deflection of a beam based on the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f019c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1' # This is a key setting\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "806baba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind dataset...\n",
      "Dataset loaded successfully.\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   k0        2000 non-null   float64\n",
      " 1   k1        2000 non-null   float64\n",
      " 2   damping   2000 non-null   int64  \n",
      " 3   velocity  2000 non-null   float64\n",
      " 4   w_max     2000 non-null   float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 78.3 KB\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   k0        2000 non-null   float64\n",
      " 1   k1        2000 non-null   float64\n",
      " 2   damping   2000 non-null   int64  \n",
      " 3   velocity  2000 non-null   float64\n",
      " 4   w_max     2000 non-null   float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 78.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "print(\"Loadind dataset...\")\n",
    "df = pd.read_csv('beam_deflection_dataset.csv')\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "339b1853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>damping</th>\n",
       "      <th>velocity</th>\n",
       "      <th>w_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.288671e+07</td>\n",
       "      <td>491480.701340</td>\n",
       "      <td>0</td>\n",
       "      <td>52.865624</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.773134e+07</td>\n",
       "      <td>327140.079848</td>\n",
       "      <td>0</td>\n",
       "      <td>71.830203</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.383103e+07</td>\n",
       "      <td>76106.954349</td>\n",
       "      <td>0</td>\n",
       "      <td>73.764909</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.274700e+06</td>\n",
       "      <td>161478.163969</td>\n",
       "      <td>0</td>\n",
       "      <td>63.154674</td>\n",
       "      <td>0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.889102e+06</td>\n",
       "      <td>246471.775806</td>\n",
       "      <td>0</td>\n",
       "      <td>16.989365</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4.155442e+07</td>\n",
       "      <td>344917.038121</td>\n",
       "      <td>0</td>\n",
       "      <td>27.219681</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.237696e+07</td>\n",
       "      <td>414292.633413</td>\n",
       "      <td>0</td>\n",
       "      <td>22.143672</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4.508789e+07</td>\n",
       "      <td>433046.020551</td>\n",
       "      <td>0</td>\n",
       "      <td>51.892469</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.097250e+07</td>\n",
       "      <td>381051.761320</td>\n",
       "      <td>0</td>\n",
       "      <td>76.768543</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3.624886e+07</td>\n",
       "      <td>377098.617153</td>\n",
       "      <td>0</td>\n",
       "      <td>23.084981</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                k0             k1  damping   velocity     w_max\n",
       "0     1.288671e+07  491480.701340        0  52.865624  0.000544\n",
       "1     1.773134e+07  327140.079848        0  71.830203  0.000618\n",
       "2     4.383103e+07   76106.954349        0  73.764909  0.000192\n",
       "3     2.274700e+06  161478.163969        0  63.154674  0.002299\n",
       "4     8.889102e+06  246471.775806        0  16.989365  0.000437\n",
       "...            ...            ...      ...        ...       ...\n",
       "1995  4.155442e+07  344917.038121        0  27.219681  0.000141\n",
       "1996  1.237696e+07  414292.633413        0  22.143672  0.000412\n",
       "1997  4.508789e+07  433046.020551        0  51.892469  0.000159\n",
       "1998  1.097250e+07  381051.761320        0  76.768543  0.000889\n",
       "1999  3.624886e+07  377098.617153        0  23.084981  0.000173\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "674c9991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>damping</th>\n",
       "      <th>velocity</th>\n",
       "      <th>w_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.288671e+07</td>\n",
       "      <td>491480.701340</td>\n",
       "      <td>0</td>\n",
       "      <td>52.865624</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.773134e+07</td>\n",
       "      <td>327140.079848</td>\n",
       "      <td>0</td>\n",
       "      <td>71.830203</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.383103e+07</td>\n",
       "      <td>76106.954349</td>\n",
       "      <td>0</td>\n",
       "      <td>73.764909</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.274700e+06</td>\n",
       "      <td>161478.163969</td>\n",
       "      <td>0</td>\n",
       "      <td>63.154674</td>\n",
       "      <td>0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.889102e+06</td>\n",
       "      <td>246471.775806</td>\n",
       "      <td>0</td>\n",
       "      <td>16.989365</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             k0             k1  damping   velocity     w_max\n",
       "0  1.288671e+07  491480.701340        0  52.865624  0.000544\n",
       "1  1.773134e+07  327140.079848        0  71.830203  0.000618\n",
       "2  4.383103e+07   76106.954349        0  73.764909  0.000192\n",
       "3  2.274700e+06  161478.163969        0  63.154674  0.002299\n",
       "4  8.889102e+06  246471.775806        0  16.989365  0.000437"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9d66cb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>damping</th>\n",
       "      <th>velocity</th>\n",
       "      <th>w_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4.155442e+07</td>\n",
       "      <td>344917.038121</td>\n",
       "      <td>0</td>\n",
       "      <td>27.219681</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.237696e+07</td>\n",
       "      <td>414292.633413</td>\n",
       "      <td>0</td>\n",
       "      <td>22.143672</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4.508789e+07</td>\n",
       "      <td>433046.020551</td>\n",
       "      <td>0</td>\n",
       "      <td>51.892469</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.097250e+07</td>\n",
       "      <td>381051.761320</td>\n",
       "      <td>0</td>\n",
       "      <td>76.768543</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3.624886e+07</td>\n",
       "      <td>377098.617153</td>\n",
       "      <td>0</td>\n",
       "      <td>23.084981</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                k0             k1  damping   velocity     w_max\n",
       "1995  4.155442e+07  344917.038121        0  27.219681  0.000141\n",
       "1996  1.237696e+07  414292.633413        0  22.143672  0.000412\n",
       "1997  4.508789e+07  433046.020551        0  51.892469  0.000159\n",
       "1998  1.097250e+07  381051.761320        0  76.768543  0.000889\n",
       "1999  3.624886e+07  377098.617153        0  23.084981  0.000173"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0f70330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Pre-processing ---\n",
    "\n",
    "# Separate the inpute features (x) from the output target (y).\n",
    "x = df[['k0', 'k1', 'damping', 'velocity']]\n",
    "y = df['w_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1013de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training + validation (85%) and testing (15%) sets.\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "555a1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 85% block into training (70%) and validation (15%)\n",
    "# The new test_size is 15/85 to get 15% of the original total data.\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=(0.15/0.85), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "48c0f652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "11086c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "19c559f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the input features\n",
    "# We fit the scaler ONLY on the training data to prvent data leakage.\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "891043fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split complete (70/15/15).\n",
      "Total samples: 2000\n",
      "Training samples: 1400\n",
      "Validation samples: 300\n",
      "Testing samples: 300\n"
     ]
    }
   ],
   "source": [
    "print(F\"\\nData split complete (70/15/15).\")\n",
    "print(F\"Total samples: {len(df)}\")\n",
    "print(F\"Training samples: {len(x_train)}\")\n",
    "print(F\"Validation samples: {len(x_val)}\")\n",
    "print(F\"Testing samples: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "42ed76b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the Neural Network Model...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Build the Neural Network Model ---\n",
    "print(\"\\nBuilding the Neural Network Model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5a8f7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer: The shape must match the number of input features (4).\n",
    "model = tf.keras.Sequential([tf.keras.layers.Input(shape=(x_train_scaled.shape[1],)),\n",
    "                             \n",
    "# Deeper and wider architecture\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2), # Add Dropout layer to prevent overfitting\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2), # Add another Dropout layer\n",
    "    \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1) # Output layer\n",
    "])\n",
    "\n",
    "# Use a lower learning rate for the Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4ae83d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "# We define the Optimizer (Adam), Loss function (Mean Squared Error), and any Metrics to track.\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0672017e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,497</span> (166.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,497\u001b[0m (166.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,497</span> (166.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,497\u001b[0m (166.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a summary of the model architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9d4ce5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.8825e-04 - mae: 0.0194 - mse: 6.8825e-04 - val_loss: 1.3885e-05 - val_mae: 0.0029 - val_mse: 1.3885e-05\n",
      "Epoch 2/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1611e-05 - mae: 0.0060 - mse: 6.1611e-05 - val_loss: 8.5435e-06 - val_mae: 0.0023 - val_mse: 8.5435e-06\n",
      "Epoch 3/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4596e-05 - mae: 0.0043 - mse: 3.4596e-05 - val_loss: 2.9967e-06 - val_mae: 0.0011 - val_mse: 2.9967e-06\n",
      "Epoch 4/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2160e-05 - mae: 0.0035 - mse: 2.2160e-05 - val_loss: 4.1434e-06 - val_mae: 0.0013 - val_mse: 4.1434e-06\n",
      "Epoch 5/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3059e-05 - mae: 0.0027 - mse: 1.3059e-05 - val_loss: 3.0451e-06 - val_mae: 8.7451e-04 - val_mse: 3.0451e-06\n",
      "Epoch 6/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6434e-06 - mae: 0.0022 - mse: 9.6434e-06 - val_loss: 3.1802e-06 - val_mae: 0.0010 - val_mse: 3.1802e-06\n",
      "Epoch 7/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6497e-06 - mae: 0.0020 - mse: 7.6497e-06 - val_loss: 2.7913e-06 - val_mae: 8.2844e-04 - val_mse: 2.7913e-06\n",
      "Epoch 8/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8531e-06 - mae: 0.0018 - mse: 5.8531e-06 - val_loss: 2.6413e-06 - val_mae: 7.3490e-04 - val_mse: 2.6413e-06\n",
      "Epoch 9/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8273e-06 - mae: 0.0016 - mse: 4.8273e-06 - val_loss: 2.5216e-06 - val_mae: 6.4434e-04 - val_mse: 2.5216e-06\n",
      "Epoch 10/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6949e-06 - mae: 0.0014 - mse: 3.6949e-06 - val_loss: 2.6870e-06 - val_mae: 8.7955e-04 - val_mse: 2.6870e-06\n",
      "Epoch 11/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1114e-06 - mae: 0.0012 - mse: 3.1114e-06 - val_loss: 2.5533e-06 - val_mae: 6.7246e-04 - val_mse: 2.5533e-06\n",
      "Epoch 12/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6529e-06 - mae: 0.0011 - mse: 2.6529e-06 - val_loss: 2.5154e-06 - val_mae: 5.5374e-04 - val_mse: 2.5154e-06\n",
      "Epoch 13/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3302e-06 - mae: 0.0010 - mse: 2.3302e-06 - val_loss: 2.5470e-06 - val_mae: 6.5747e-04 - val_mse: 2.5470e-06\n",
      "Epoch 14/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8729e-06 - mae: 9.4072e-04 - mse: 1.8729e-06 - val_loss: 2.4526e-06 - val_mae: 5.0623e-04 - val_mse: 2.4526e-06\n",
      "Epoch 15/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6802e-06 - mae: 8.8751e-04 - mse: 1.6802e-06 - val_loss: 2.3496e-06 - val_mae: 4.7130e-04 - val_mse: 2.3496e-06\n",
      "Epoch 16/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3103e-06 - mae: 7.5991e-04 - mse: 1.3103e-06 - val_loss: 2.4035e-06 - val_mae: 4.6104e-04 - val_mse: 2.4035e-06\n",
      "Epoch 17/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2206e-06 - mae: 6.9672e-04 - mse: 1.2206e-06 - val_loss: 2.2977e-06 - val_mae: 4.6644e-04 - val_mse: 2.2977e-06\n",
      "Epoch 18/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1485e-06 - mae: 6.8284e-04 - mse: 1.1485e-06 - val_loss: 2.3440e-06 - val_mae: 4.4651e-04 - val_mse: 2.3440e-06\n",
      "Epoch 19/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3531e-07 - mae: 6.3337e-04 - mse: 9.3531e-07 - val_loss: 2.2228e-06 - val_mae: 4.5577e-04 - val_mse: 2.2228e-06\n",
      "Epoch 20/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3972e-07 - mae: 6.2738e-04 - mse: 9.3972e-07 - val_loss: 2.2642e-06 - val_mae: 3.8716e-04 - val_mse: 2.2642e-06\n",
      "Epoch 21/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0161e-06 - mae: 6.2836e-04 - mse: 1.0161e-06 - val_loss: 2.2211e-06 - val_mae: 3.8667e-04 - val_mse: 2.2211e-06\n",
      "Epoch 22/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3082e-07 - mae: 5.6936e-04 - mse: 8.3082e-07 - val_loss: 2.2173e-06 - val_mae: 4.0757e-04 - val_mse: 2.2173e-06\n",
      "Epoch 23/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4227e-07 - mae: 5.6155e-04 - mse: 8.4227e-07 - val_loss: 2.2201e-06 - val_mae: 4.9241e-04 - val_mse: 2.2201e-06\n",
      "Epoch 24/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7347e-07 - mae: 5.5591e-04 - mse: 8.7347e-07 - val_loss: 2.2091e-06 - val_mae: 5.4256e-04 - val_mse: 2.2091e-06\n",
      "Epoch 25/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2885e-07 - mae: 5.3660e-04 - mse: 8.2885e-07 - val_loss: 2.2216e-06 - val_mae: 3.7410e-04 - val_mse: 2.2216e-06\n",
      "Epoch 26/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9549e-07 - mae: 5.2228e-04 - mse: 7.9549e-07 - val_loss: 2.1863e-06 - val_mae: 4.0283e-04 - val_mse: 2.1863e-06\n",
      "Epoch 27/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8212e-07 - mae: 4.9183e-04 - mse: 6.8212e-07 - val_loss: 2.2264e-06 - val_mae: 6.2080e-04 - val_mse: 2.2264e-06\n",
      "Epoch 28/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1123e-07 - mae: 5.1180e-04 - mse: 7.1123e-07 - val_loss: 2.1329e-06 - val_mae: 4.7770e-04 - val_mse: 2.1329e-06\n",
      "Epoch 29/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2694e-07 - mae: 4.6857e-04 - mse: 6.2694e-07 - val_loss: 2.1134e-06 - val_mae: 4.1166e-04 - val_mse: 2.1134e-06\n",
      "Epoch 30/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8535e-07 - mae: 4.5706e-04 - mse: 5.8535e-07 - val_loss: 2.1280e-06 - val_mae: 3.5530e-04 - val_mse: 2.1280e-06\n",
      "Epoch 31/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9585e-07 - mae: 4.6200e-04 - mse: 5.9585e-07 - val_loss: 2.1572e-06 - val_mae: 3.3257e-04 - val_mse: 2.1572e-06\n",
      "Epoch 32/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1973e-07 - mae: 4.1327e-04 - mse: 5.1973e-07 - val_loss: 2.0756e-06 - val_mae: 3.7943e-04 - val_mse: 2.0756e-06\n",
      "Epoch 33/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3505e-07 - mae: 4.0316e-04 - mse: 5.3505e-07 - val_loss: 2.0871e-06 - val_mae: 4.8093e-04 - val_mse: 2.0871e-06\n",
      "Epoch 34/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0370e-07 - mae: 4.5690e-04 - mse: 6.0370e-07 - val_loss: 2.0216e-06 - val_mae: 3.7297e-04 - val_mse: 2.0216e-06\n",
      "Epoch 35/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9697e-07 - mae: 3.8848e-04 - mse: 4.9697e-07 - val_loss: 1.9761e-06 - val_mae: 3.8059e-04 - val_mse: 1.9761e-06\n",
      "Epoch 36/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7678e-07 - mae: 4.3551e-04 - mse: 5.7678e-07 - val_loss: 2.0146e-06 - val_mae: 3.1450e-04 - val_mse: 2.0146e-06\n",
      "Epoch 37/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7178e-07 - mae: 3.7396e-04 - mse: 4.7178e-07 - val_loss: 1.9855e-06 - val_mae: 4.3603e-04 - val_mse: 1.9855e-06\n",
      "Epoch 38/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7701e-07 - mae: 3.8742e-04 - mse: 4.7701e-07 - val_loss: 1.9923e-06 - val_mae: 4.1299e-04 - val_mse: 1.9923e-06\n",
      "Epoch 39/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6860e-07 - mae: 3.7337e-04 - mse: 4.6860e-07 - val_loss: 1.9561e-06 - val_mae: 3.9503e-04 - val_mse: 1.9561e-06\n",
      "Epoch 40/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6048e-07 - mae: 3.6996e-04 - mse: 4.6048e-07 - val_loss: 1.9437e-06 - val_mae: 3.3571e-04 - val_mse: 1.9437e-06\n",
      "Epoch 41/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9160e-07 - mae: 3.4230e-04 - mse: 3.9160e-07 - val_loss: 1.9653e-06 - val_mae: 5.5925e-04 - val_mse: 1.9653e-06\n",
      "Epoch 42/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4597e-07 - mae: 4.4673e-04 - mse: 5.4597e-07 - val_loss: 1.9152e-06 - val_mae: 4.4581e-04 - val_mse: 1.9152e-06\n",
      "Epoch 43/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9942e-07 - mae: 3.9808e-04 - mse: 5.9942e-07 - val_loss: 1.9369e-06 - val_mae: 5.1870e-04 - val_mse: 1.9369e-06\n",
      "Epoch 44/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3108e-07 - mae: 3.6689e-04 - mse: 4.3108e-07 - val_loss: 1.8564e-06 - val_mae: 3.6678e-04 - val_mse: 1.8564e-06\n",
      "Epoch 45/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0743e-07 - mae: 3.5747e-04 - mse: 4.0743e-07 - val_loss: 1.8803e-06 - val_mae: 2.8949e-04 - val_mse: 1.8803e-06\n",
      "Epoch 46/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9396e-07 - mae: 2.7558e-04 - mse: 2.9396e-07 - val_loss: 1.7901e-06 - val_mae: 2.7183e-04 - val_mse: 1.7901e-06\n",
      "Epoch 47/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1097e-07 - mae: 3.2921e-04 - mse: 4.1097e-07 - val_loss: 1.8551e-06 - val_mae: 5.0453e-04 - val_mse: 1.8551e-06\n",
      "Epoch 48/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6210e-07 - mae: 3.9881e-04 - mse: 4.6210e-07 - val_loss: 1.7600e-06 - val_mae: 2.8483e-04 - val_mse: 1.7600e-06\n",
      "Epoch 49/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3532e-07 - mae: 3.2732e-04 - mse: 3.3532e-07 - val_loss: 1.7447e-06 - val_mae: 2.9654e-04 - val_mse: 1.7447e-06\n",
      "Epoch 50/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3765e-07 - mae: 3.2927e-04 - mse: 4.3765e-07 - val_loss: 1.7007e-06 - val_mae: 3.0147e-04 - val_mse: 1.7007e-06\n",
      "Epoch 51/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5083e-07 - mae: 3.1373e-04 - mse: 3.5083e-07 - val_loss: 1.7283e-06 - val_mae: 2.5316e-04 - val_mse: 1.7283e-06\n",
      "Epoch 52/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9079e-07 - mae: 2.9557e-04 - mse: 3.9079e-07 - val_loss: 1.6498e-06 - val_mae: 2.6735e-04 - val_mse: 1.6498e-06\n",
      "Epoch 53/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5125e-07 - mae: 3.1782e-04 - mse: 3.5125e-07 - val_loss: 1.6471e-06 - val_mae: 2.6568e-04 - val_mse: 1.6471e-06\n",
      "Epoch 54/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6533e-07 - mae: 3.0377e-04 - mse: 3.6533e-07 - val_loss: 1.6184e-06 - val_mae: 2.8858e-04 - val_mse: 1.6184e-06\n",
      "Epoch 55/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4675e-07 - mae: 2.8960e-04 - mse: 3.4675e-07 - val_loss: 1.7074e-06 - val_mae: 3.5710e-04 - val_mse: 1.7074e-06\n",
      "Epoch 56/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5693e-07 - mae: 3.1443e-04 - mse: 3.5693e-07 - val_loss: 1.6456e-06 - val_mae: 4.1229e-04 - val_mse: 1.6456e-06\n",
      "Epoch 57/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4953e-07 - mae: 3.3804e-04 - mse: 3.4953e-07 - val_loss: 1.6306e-06 - val_mae: 2.5285e-04 - val_mse: 1.6306e-06\n",
      "Epoch 58/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8699e-07 - mae: 2.6851e-04 - mse: 2.8699e-07 - val_loss: 1.6018e-06 - val_mae: 2.5656e-04 - val_mse: 1.6018e-06\n",
      "Epoch 59/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5959e-07 - mae: 2.4620e-04 - mse: 2.5959e-07 - val_loss: 1.5500e-06 - val_mae: 2.8886e-04 - val_mse: 1.5500e-06\n",
      "Epoch 60/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4395e-07 - mae: 2.8299e-04 - mse: 3.4395e-07 - val_loss: 1.5388e-06 - val_mae: 2.3779e-04 - val_mse: 1.5388e-06\n",
      "Epoch 61/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2077e-07 - mae: 2.9840e-04 - mse: 3.2077e-07 - val_loss: 1.5458e-06 - val_mae: 2.9334e-04 - val_mse: 1.5458e-06\n",
      "Epoch 62/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3422e-07 - mae: 3.1415e-04 - mse: 3.3422e-07 - val_loss: 1.5123e-06 - val_mae: 3.3513e-04 - val_mse: 1.5123e-06\n",
      "Epoch 63/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8278e-07 - mae: 3.0100e-04 - mse: 2.8278e-07 - val_loss: 1.7584e-06 - val_mae: 5.9214e-04 - val_mse: 1.7584e-06\n",
      "Epoch 64/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9630e-07 - mae: 3.7454e-04 - mse: 3.9630e-07 - val_loss: 1.4592e-06 - val_mae: 2.7761e-04 - val_mse: 1.4592e-06\n",
      "Epoch 65/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7643e-07 - mae: 2.7644e-04 - mse: 2.7643e-07 - val_loss: 1.4927e-06 - val_mae: 2.7983e-04 - val_mse: 1.4927e-06\n",
      "Epoch 66/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6175e-07 - mae: 2.5954e-04 - mse: 2.6175e-07 - val_loss: 1.4637e-06 - val_mae: 2.6728e-04 - val_mse: 1.4637e-06\n",
      "Epoch 67/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9306e-07 - mae: 2.6691e-04 - mse: 2.9306e-07 - val_loss: 1.6009e-06 - val_mae: 4.8196e-04 - val_mse: 1.6009e-06\n",
      "Epoch 68/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8573e-07 - mae: 2.8430e-04 - mse: 2.8573e-07 - val_loss: 1.4341e-06 - val_mae: 2.6112e-04 - val_mse: 1.4341e-06\n",
      "Epoch 69/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5124e-07 - mae: 2.5996e-04 - mse: 2.5124e-07 - val_loss: 1.4274e-06 - val_mae: 2.8531e-04 - val_mse: 1.4274e-06\n",
      "Epoch 70/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8082e-07 - mae: 2.6161e-04 - mse: 2.8082e-07 - val_loss: 1.4752e-06 - val_mae: 3.1592e-04 - val_mse: 1.4752e-06\n",
      "Epoch 71/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3078e-07 - mae: 2.7074e-04 - mse: 3.3078e-07 - val_loss: 1.4089e-06 - val_mae: 2.5713e-04 - val_mse: 1.4089e-06\n",
      "Epoch 72/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3547e-07 - mae: 2.3892e-04 - mse: 2.3547e-07 - val_loss: 1.4279e-06 - val_mae: 2.5778e-04 - val_mse: 1.4279e-06\n",
      "Epoch 73/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8716e-07 - mae: 2.6367e-04 - mse: 2.8716e-07 - val_loss: 1.4717e-06 - val_mae: 3.5653e-04 - val_mse: 1.4717e-06\n",
      "Epoch 74/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7436e-07 - mae: 2.7340e-04 - mse: 2.7436e-07 - val_loss: 1.4282e-06 - val_mae: 2.4259e-04 - val_mse: 1.4282e-06\n",
      "Epoch 75/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1396e-07 - mae: 2.1951e-04 - mse: 2.1396e-07 - val_loss: 1.5046e-06 - val_mae: 4.3491e-04 - val_mse: 1.5046e-06\n",
      "Epoch 76/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0861e-07 - mae: 2.9528e-04 - mse: 3.0861e-07 - val_loss: 1.5102e-06 - val_mae: 4.5079e-04 - val_mse: 1.5102e-06\n",
      "Epoch 77/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7083e-07 - mae: 3.1787e-04 - mse: 2.7083e-07 - val_loss: 1.3886e-06 - val_mae: 2.3446e-04 - val_mse: 1.3886e-06\n",
      "Epoch 78/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2256e-07 - mae: 2.2430e-04 - mse: 2.2256e-07 - val_loss: 1.3913e-06 - val_mae: 2.9326e-04 - val_mse: 1.3913e-06\n",
      "Epoch 79/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1297e-07 - mae: 2.6718e-04 - mse: 3.1297e-07 - val_loss: 1.5155e-06 - val_mae: 3.5963e-04 - val_mse: 1.5155e-06\n",
      "Epoch 80/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4009e-07 - mae: 2.5472e-04 - mse: 2.4009e-07 - val_loss: 1.3601e-06 - val_mae: 2.3426e-04 - val_mse: 1.3601e-06\n",
      "Epoch 81/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0007e-07 - mae: 2.2337e-04 - mse: 2.0007e-07 - val_loss: 1.3290e-06 - val_mae: 2.3255e-04 - val_mse: 1.3290e-06\n",
      "Epoch 82/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9043e-07 - mae: 2.2630e-04 - mse: 1.9043e-07 - val_loss: 1.3136e-06 - val_mae: 2.3284e-04 - val_mse: 1.3136e-06\n",
      "Epoch 83/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7148e-07 - mae: 2.2385e-04 - mse: 1.7148e-07 - val_loss: 1.3930e-06 - val_mae: 2.5468e-04 - val_mse: 1.3930e-06\n",
      "Epoch 84/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4367e-07 - mae: 2.6416e-04 - mse: 2.4367e-07 - val_loss: 1.3048e-06 - val_mae: 2.6041e-04 - val_mse: 1.3048e-06\n",
      "Epoch 85/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2889e-07 - mae: 2.6417e-04 - mse: 2.2889e-07 - val_loss: 1.3664e-06 - val_mae: 4.0686e-04 - val_mse: 1.3664e-06\n",
      "Epoch 86/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7061e-07 - mae: 2.7886e-04 - mse: 2.7061e-07 - val_loss: 1.3230e-06 - val_mae: 2.5685e-04 - val_mse: 1.3230e-06\n",
      "Epoch 87/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0075e-07 - mae: 2.5309e-04 - mse: 2.0075e-07 - val_loss: 1.3697e-06 - val_mae: 4.2385e-04 - val_mse: 1.3697e-06\n",
      "Epoch 88/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6209e-07 - mae: 2.7589e-04 - mse: 2.6209e-07 - val_loss: 1.3017e-06 - val_mae: 2.8379e-04 - val_mse: 1.3017e-06\n",
      "Epoch 89/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3166e-07 - mae: 2.5974e-04 - mse: 2.3166e-07 - val_loss: 1.4354e-06 - val_mae: 3.3851e-04 - val_mse: 1.4354e-06\n",
      "Epoch 90/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1536e-07 - mae: 2.5476e-04 - mse: 2.1536e-07 - val_loss: 1.2323e-06 - val_mae: 2.7125e-04 - val_mse: 1.2323e-06\n",
      "Epoch 91/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2075e-07 - mae: 2.4266e-04 - mse: 2.2075e-07 - val_loss: 1.1551e-06 - val_mae: 2.2558e-04 - val_mse: 1.1551e-06\n",
      "Epoch 92/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3498e-07 - mae: 2.6929e-04 - mse: 2.3498e-07 - val_loss: 1.2150e-06 - val_mae: 1.9701e-04 - val_mse: 1.2150e-06\n",
      "Epoch 93/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0745e-07 - mae: 2.6196e-04 - mse: 2.0745e-07 - val_loss: 1.1715e-06 - val_mae: 3.1953e-04 - val_mse: 1.1715e-06\n",
      "Epoch 94/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4227e-07 - mae: 2.4741e-04 - mse: 2.4227e-07 - val_loss: 1.2190e-06 - val_mae: 2.1746e-04 - val_mse: 1.2190e-06\n",
      "Epoch 95/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8763e-07 - mae: 2.2209e-04 - mse: 1.8763e-07 - val_loss: 1.1512e-06 - val_mae: 1.9644e-04 - val_mse: 1.1512e-06\n",
      "Epoch 96/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0530e-07 - mae: 2.3585e-04 - mse: 2.0530e-07 - val_loss: 1.1647e-06 - val_mae: 2.9370e-04 - val_mse: 1.1647e-06\n",
      "Epoch 97/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1823e-07 - mae: 2.4330e-04 - mse: 2.1823e-07 - val_loss: 1.1685e-06 - val_mae: 2.1828e-04 - val_mse: 1.1685e-06\n",
      "Epoch 98/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2267e-07 - mae: 2.7018e-04 - mse: 2.2267e-07 - val_loss: 1.1863e-06 - val_mae: 1.9387e-04 - val_mse: 1.1863e-06\n",
      "Epoch 99/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8305e-07 - mae: 2.3138e-04 - mse: 1.8305e-07 - val_loss: 1.1928e-06 - val_mae: 1.9537e-04 - val_mse: 1.1928e-06\n",
      "Epoch 100/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1477e-07 - mae: 2.6563e-04 - mse: 2.1477e-07 - val_loss: 1.3041e-06 - val_mae: 2.4883e-04 - val_mse: 1.3041e-06\n",
      "Epoch 101/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4987e-07 - mae: 1.9807e-04 - mse: 1.4987e-07 - val_loss: 1.1710e-06 - val_mae: 2.9339e-04 - val_mse: 1.1710e-06\n",
      "Epoch 102/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2964e-07 - mae: 2.8328e-04 - mse: 2.2964e-07 - val_loss: 1.1200e-06 - val_mae: 2.3303e-04 - val_mse: 1.1200e-06\n",
      "Epoch 103/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2745e-07 - mae: 2.6821e-04 - mse: 2.2745e-07 - val_loss: 1.1390e-06 - val_mae: 2.7925e-04 - val_mse: 1.1390e-06\n",
      "Epoch 104/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8653e-07 - mae: 2.4711e-04 - mse: 1.8653e-07 - val_loss: 1.1811e-06 - val_mae: 2.8088e-04 - val_mse: 1.1811e-06\n",
      "Epoch 105/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9609e-07 - mae: 2.3624e-04 - mse: 1.9609e-07 - val_loss: 1.1225e-06 - val_mae: 2.9249e-04 - val_mse: 1.1225e-06\n",
      "Epoch 106/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8870e-07 - mae: 2.3055e-04 - mse: 1.8870e-07 - val_loss: 1.1327e-06 - val_mae: 2.5433e-04 - val_mse: 1.1327e-06\n",
      "Epoch 107/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6059e-07 - mae: 2.1100e-04 - mse: 1.6059e-07 - val_loss: 1.1778e-06 - val_mae: 3.3551e-04 - val_mse: 1.1778e-06\n",
      "Epoch 108/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6640e-07 - mae: 2.1760e-04 - mse: 1.6640e-07 - val_loss: 1.2558e-06 - val_mae: 2.5923e-04 - val_mse: 1.2558e-06\n",
      "Epoch 109/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6352e-07 - mae: 2.3337e-04 - mse: 1.6352e-07 - val_loss: 1.1862e-06 - val_mae: 2.9594e-04 - val_mse: 1.1862e-06\n",
      "Epoch 110/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5616e-07 - mae: 2.1682e-04 - mse: 1.5616e-07 - val_loss: 1.1678e-06 - val_mae: 3.9166e-04 - val_mse: 1.1678e-06\n",
      "Epoch 111/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6763e-07 - mae: 2.3844e-04 - mse: 1.6763e-07 - val_loss: 1.1467e-06 - val_mae: 2.2122e-04 - val_mse: 1.1467e-06\n",
      "Epoch 112/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4114e-07 - mae: 1.8844e-04 - mse: 1.4114e-07 - val_loss: 1.1609e-06 - val_mae: 2.3732e-04 - val_mse: 1.1609e-06\n",
      "Epoch 113/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5972e-07 - mae: 1.9174e-04 - mse: 1.5972e-07 - val_loss: 1.1922e-06 - val_mae: 3.4932e-04 - val_mse: 1.1922e-06\n",
      "Epoch 114/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9684e-07 - mae: 2.5187e-04 - mse: 1.9684e-07 - val_loss: 1.0919e-06 - val_mae: 2.4926e-04 - val_mse: 1.0919e-06\n",
      "Epoch 115/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8178e-07 - mae: 2.1187e-04 - mse: 1.8178e-07 - val_loss: 1.1104e-06 - val_mae: 2.3200e-04 - val_mse: 1.1104e-06\n",
      "Epoch 116/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4689e-07 - mae: 2.0432e-04 - mse: 1.4689e-07 - val_loss: 1.0895e-06 - val_mae: 1.9120e-04 - val_mse: 1.0895e-06\n",
      "Epoch 117/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7273e-07 - mae: 2.4006e-04 - mse: 1.7273e-07 - val_loss: 1.0694e-06 - val_mae: 3.4771e-04 - val_mse: 1.0694e-06\n",
      "Epoch 118/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4268e-07 - mae: 2.7135e-04 - mse: 1.4268e-07 - val_loss: 1.0002e-06 - val_mae: 2.1888e-04 - val_mse: 1.0002e-06\n",
      "Epoch 119/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2181e-07 - mae: 1.7700e-04 - mse: 1.2181e-07 - val_loss: 1.1100e-06 - val_mae: 2.0142e-04 - val_mse: 1.1100e-06\n",
      "Epoch 120/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4248e-07 - mae: 2.1890e-04 - mse: 1.4248e-07 - val_loss: 1.0900e-06 - val_mae: 2.4317e-04 - val_mse: 1.0900e-06\n",
      "Epoch 121/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9962e-07 - mae: 2.5060e-04 - mse: 1.9962e-07 - val_loss: 1.2086e-06 - val_mae: 4.6827e-04 - val_mse: 1.2086e-06\n",
      "Epoch 122/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1136e-07 - mae: 2.6608e-04 - mse: 2.1136e-07 - val_loss: 1.1434e-06 - val_mae: 3.8548e-04 - val_mse: 1.1434e-06\n",
      "Epoch 123/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5605e-07 - mae: 2.3044e-04 - mse: 1.5605e-07 - val_loss: 1.0882e-06 - val_mae: 3.2237e-04 - val_mse: 1.0882e-06\n",
      "Epoch 124/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3524e-07 - mae: 2.2694e-04 - mse: 1.3524e-07 - val_loss: 9.8780e-07 - val_mae: 2.7866e-04 - val_mse: 9.8780e-07\n",
      "Epoch 125/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6451e-07 - mae: 2.3740e-04 - mse: 1.6451e-07 - val_loss: 1.2179e-06 - val_mae: 4.3124e-04 - val_mse: 1.2179e-06\n",
      "Epoch 126/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5040e-07 - mae: 2.6528e-04 - mse: 1.5040e-07 - val_loss: 1.1802e-06 - val_mae: 4.9788e-04 - val_mse: 1.1802e-06\n",
      "Epoch 127/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8791e-07 - mae: 2.7775e-04 - mse: 1.8791e-07 - val_loss: 1.1461e-06 - val_mae: 3.4409e-04 - val_mse: 1.1461e-06\n",
      "Epoch 128/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0165e-07 - mae: 2.9177e-04 - mse: 2.0165e-07 - val_loss: 1.1173e-06 - val_mae: 3.3140e-04 - val_mse: 1.1173e-06\n",
      "Epoch 129/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0696e-07 - mae: 2.9006e-04 - mse: 2.0696e-07 - val_loss: 9.6305e-07 - val_mae: 2.8275e-04 - val_mse: 9.6305e-07\n",
      "Epoch 130/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5646e-07 - mae: 2.4947e-04 - mse: 1.5646e-07 - val_loss: 1.0239e-06 - val_mae: 2.6491e-04 - val_mse: 1.0239e-06\n",
      "Epoch 131/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1618e-07 - mae: 1.9195e-04 - mse: 1.1618e-07 - val_loss: 9.8239e-07 - val_mae: 3.2915e-04 - val_mse: 9.8239e-07\n",
      "Epoch 132/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9748e-07 - mae: 2.5159e-04 - mse: 1.9748e-07 - val_loss: 1.0238e-06 - val_mae: 3.6250e-04 - val_mse: 1.0238e-06\n",
      "Epoch 133/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1185e-07 - mae: 2.5332e-04 - mse: 2.1185e-07 - val_loss: 1.0235e-06 - val_mae: 2.1183e-04 - val_mse: 1.0235e-06\n",
      "Epoch 134/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0769e-07 - mae: 1.9075e-04 - mse: 1.0769e-07 - val_loss: 1.0862e-06 - val_mae: 2.2611e-04 - val_mse: 1.0862e-06\n",
      "Epoch 135/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1231e-07 - mae: 1.6778e-04 - mse: 1.1231e-07 - val_loss: 1.0979e-06 - val_mae: 2.5426e-04 - val_mse: 1.0979e-06\n",
      "Epoch 136/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4816e-07 - mae: 1.9097e-04 - mse: 1.4816e-07 - val_loss: 1.0966e-06 - val_mae: 2.1174e-04 - val_mse: 1.0966e-06\n",
      "Epoch 137/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2713e-07 - mae: 1.7528e-04 - mse: 1.2713e-07 - val_loss: 1.0924e-06 - val_mae: 1.7497e-04 - val_mse: 1.0924e-06\n",
      "Epoch 138/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3038e-07 - mae: 1.8460e-04 - mse: 1.3038e-07 - val_loss: 1.1003e-06 - val_mae: 3.3078e-04 - val_mse: 1.1003e-06\n",
      "Epoch 139/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3885e-07 - mae: 2.3119e-04 - mse: 1.3885e-07 - val_loss: 9.8080e-07 - val_mae: 1.6890e-04 - val_mse: 9.8080e-07\n",
      "Epoch 140/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8231e-07 - mae: 2.4239e-04 - mse: 1.8231e-07 - val_loss: 1.0938e-06 - val_mae: 2.5869e-04 - val_mse: 1.0938e-06\n",
      "Epoch 141/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7354e-07 - mae: 2.5152e-04 - mse: 1.7354e-07 - val_loss: 1.1251e-06 - val_mae: 2.7293e-04 - val_mse: 1.1251e-06\n",
      "Epoch 142/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1753e-07 - mae: 1.9880e-04 - mse: 1.1753e-07 - val_loss: 1.1110e-06 - val_mae: 1.9637e-04 - val_mse: 1.1110e-06\n",
      "Epoch 143/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3720e-07 - mae: 1.8775e-04 - mse: 1.3720e-07 - val_loss: 1.3716e-06 - val_mae: 4.4475e-04 - val_mse: 1.3716e-06\n",
      "Epoch 144/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6184e-07 - mae: 2.4061e-04 - mse: 1.6184e-07 - val_loss: 1.1345e-06 - val_mae: 3.4450e-04 - val_mse: 1.1345e-06\n",
      "Epoch 145/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3609e-07 - mae: 2.3769e-04 - mse: 1.3609e-07 - val_loss: 1.1507e-06 - val_mae: 2.3265e-04 - val_mse: 1.1507e-06\n",
      "Epoch 146/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0910e-07 - mae: 1.8700e-04 - mse: 1.0910e-07 - val_loss: 9.2815e-07 - val_mae: 2.2201e-04 - val_mse: 9.2815e-07\n",
      "Epoch 147/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0890e-07 - mae: 1.9432e-04 - mse: 1.0890e-07 - val_loss: 1.0121e-06 - val_mae: 2.5960e-04 - val_mse: 1.0121e-06\n",
      "Epoch 148/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2105e-08 - mae: 1.8404e-04 - mse: 9.2105e-08 - val_loss: 1.0708e-06 - val_mae: 2.0078e-04 - val_mse: 1.0708e-06\n",
      "Epoch 149/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2941e-07 - mae: 1.8711e-04 - mse: 1.2941e-07 - val_loss: 1.1455e-06 - val_mae: 4.5641e-04 - val_mse: 1.1455e-06\n",
      "Epoch 150/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5865e-07 - mae: 2.6137e-04 - mse: 1.5865e-07 - val_loss: 9.8896e-07 - val_mae: 2.5123e-04 - val_mse: 9.8896e-07\n",
      "Epoch 151/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3419e-07 - mae: 2.3653e-04 - mse: 1.3419e-07 - val_loss: 9.4349e-07 - val_mae: 1.7467e-04 - val_mse: 9.4349e-07\n",
      "Epoch 152/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8629e-08 - mae: 1.8423e-04 - mse: 8.8629e-08 - val_loss: 1.0363e-06 - val_mae: 2.3876e-04 - val_mse: 1.0363e-06\n",
      "Epoch 153/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1210e-07 - mae: 1.8439e-04 - mse: 1.1210e-07 - val_loss: 1.1055e-06 - val_mae: 2.8824e-04 - val_mse: 1.1055e-06\n",
      "Epoch 154/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0383e-07 - mae: 1.8313e-04 - mse: 1.0383e-07 - val_loss: 1.0046e-06 - val_mae: 2.3049e-04 - val_mse: 1.0046e-06\n",
      "Epoch 155/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5396e-08 - mae: 1.8732e-04 - mse: 9.5396e-08 - val_loss: 1.0664e-06 - val_mae: 2.0690e-04 - val_mse: 1.0664e-06\n",
      "Epoch 156/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0966e-07 - mae: 1.8301e-04 - mse: 1.0966e-07 - val_loss: 1.0351e-06 - val_mae: 1.9088e-04 - val_mse: 1.0351e-06\n",
      "Epoch 157/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2661e-07 - mae: 2.4244e-04 - mse: 1.2661e-07 - val_loss: 9.2729e-07 - val_mae: 2.0671e-04 - val_mse: 9.2729e-07\n",
      "Epoch 158/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2055e-07 - mae: 1.9298e-04 - mse: 1.2055e-07 - val_loss: 9.5257e-07 - val_mae: 1.8230e-04 - val_mse: 9.5257e-07\n",
      "Epoch 159/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7480e-08 - mae: 1.7732e-04 - mse: 8.7480e-08 - val_loss: 9.6075e-07 - val_mae: 2.5852e-04 - val_mse: 9.6075e-07\n",
      "Epoch 160/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6836e-08 - mae: 1.7140e-04 - mse: 7.6836e-08 - val_loss: 9.1503e-07 - val_mae: 1.5983e-04 - val_mse: 9.1503e-07\n",
      "Epoch 161/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2816e-07 - mae: 1.9575e-04 - mse: 1.2816e-07 - val_loss: 9.0293e-07 - val_mae: 2.0483e-04 - val_mse: 9.0293e-07\n",
      "Epoch 162/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6698e-07 - mae: 2.5580e-04 - mse: 1.6698e-07 - val_loss: 8.9131e-07 - val_mae: 1.8887e-04 - val_mse: 8.9131e-07\n",
      "Epoch 163/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3083e-08 - mae: 1.9328e-04 - mse: 9.3083e-08 - val_loss: 9.6421e-07 - val_mae: 1.9233e-04 - val_mse: 9.6421e-07\n",
      "Epoch 164/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4092e-07 - mae: 2.3200e-04 - mse: 1.4092e-07 - val_loss: 9.2693e-07 - val_mae: 2.7784e-04 - val_mse: 9.2693e-07\n",
      "Epoch 165/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0596e-07 - mae: 1.9990e-04 - mse: 1.0596e-07 - val_loss: 1.0326e-06 - val_mae: 2.3898e-04 - val_mse: 1.0326e-06\n",
      "Epoch 166/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3649e-07 - mae: 2.0835e-04 - mse: 1.3649e-07 - val_loss: 9.2252e-07 - val_mae: 1.6874e-04 - val_mse: 9.2252e-07\n",
      "Epoch 167/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6698e-08 - mae: 1.7120e-04 - mse: 7.6698e-08 - val_loss: 1.0517e-06 - val_mae: 2.3960e-04 - val_mse: 1.0517e-06\n",
      "Epoch 168/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5404e-07 - mae: 2.2443e-04 - mse: 1.5404e-07 - val_loss: 9.4145e-07 - val_mae: 1.9300e-04 - val_mse: 9.4145e-07\n",
      "Epoch 169/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4000e-07 - mae: 2.5254e-04 - mse: 1.4000e-07 - val_loss: 9.5729e-07 - val_mae: 2.0780e-04 - val_mse: 9.5729e-07\n",
      "Epoch 170/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9679e-08 - mae: 1.8999e-04 - mse: 9.9679e-08 - val_loss: 1.0611e-06 - val_mae: 2.2659e-04 - val_mse: 1.0611e-06\n",
      "Epoch 171/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2140e-07 - mae: 2.0924e-04 - mse: 1.2140e-07 - val_loss: 1.0813e-06 - val_mae: 3.0499e-04 - val_mse: 1.0813e-06\n",
      "Epoch 172/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6173e-07 - mae: 1.9599e-04 - mse: 1.6173e-07 - val_loss: 1.0016e-06 - val_mae: 2.1952e-04 - val_mse: 1.0016e-06\n",
      "Epoch 173/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3351e-07 - mae: 2.3040e-04 - mse: 1.3351e-07 - val_loss: 9.6785e-07 - val_mae: 1.8475e-04 - val_mse: 9.6785e-07\n",
      "Epoch 174/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3424e-08 - mae: 1.7871e-04 - mse: 9.3424e-08 - val_loss: 1.0939e-06 - val_mae: 2.6739e-04 - val_mse: 1.0939e-06\n",
      "Epoch 175/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2652e-07 - mae: 2.0036e-04 - mse: 1.2652e-07 - val_loss: 9.2701e-07 - val_mae: 1.5969e-04 - val_mse: 9.2701e-07\n",
      "Epoch 176/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3388e-07 - mae: 2.5454e-04 - mse: 1.3388e-07 - val_loss: 9.9995e-07 - val_mae: 2.2595e-04 - val_mse: 9.9995e-07\n",
      "Epoch 177/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1717e-07 - mae: 1.9214e-04 - mse: 1.1717e-07 - val_loss: 8.7320e-07 - val_mae: 2.0106e-04 - val_mse: 8.7320e-07\n",
      "Epoch 178/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1497e-07 - mae: 2.2178e-04 - mse: 1.1497e-07 - val_loss: 8.7807e-07 - val_mae: 1.7293e-04 - val_mse: 8.7807e-07\n",
      "Epoch 179/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0526e-07 - mae: 2.0012e-04 - mse: 1.0526e-07 - val_loss: 1.3102e-06 - val_mae: 3.1118e-04 - val_mse: 1.3102e-06\n",
      "Epoch 180/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0870e-07 - mae: 1.7307e-04 - mse: 1.0870e-07 - val_loss: 1.0582e-06 - val_mae: 2.1295e-04 - val_mse: 1.0582e-06\n",
      "Epoch 181/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6621e-08 - mae: 2.1657e-04 - mse: 9.6621e-08 - val_loss: 9.1603e-07 - val_mae: 2.4094e-04 - val_mse: 9.1603e-07\n",
      "Epoch 182/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2841e-08 - mae: 1.5534e-04 - mse: 7.2841e-08 - val_loss: 1.0187e-06 - val_mae: 2.0328e-04 - val_mse: 1.0187e-06\n",
      "Epoch 183/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2971e-08 - mae: 1.5748e-04 - mse: 8.2971e-08 - val_loss: 1.0538e-06 - val_mae: 1.8086e-04 - val_mse: 1.0538e-06\n",
      "Epoch 184/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4381e-08 - mae: 1.5796e-04 - mse: 8.4381e-08 - val_loss: 9.2021e-07 - val_mae: 2.3051e-04 - val_mse: 9.2021e-07\n",
      "Epoch 185/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7528e-08 - mae: 1.6214e-04 - mse: 7.7528e-08 - val_loss: 9.2343e-07 - val_mae: 1.3352e-04 - val_mse: 9.2343e-07\n",
      "Epoch 186/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8559e-08 - mae: 1.8623e-04 - mse: 8.8559e-08 - val_loss: 9.7576e-07 - val_mae: 2.0245e-04 - val_mse: 9.7576e-07\n",
      "Epoch 187/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0864e-07 - mae: 1.9037e-04 - mse: 1.0864e-07 - val_loss: 1.0795e-06 - val_mae: 1.9376e-04 - val_mse: 1.0795e-06\n",
      "Epoch 188/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7476e-08 - mae: 1.6654e-04 - mse: 9.7476e-08 - val_loss: 8.7443e-07 - val_mae: 1.5334e-04 - val_mse: 8.7443e-07\n",
      "Epoch 189/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0346e-07 - mae: 1.9223e-04 - mse: 1.0346e-07 - val_loss: 9.2767e-07 - val_mae: 1.4915e-04 - val_mse: 9.2767e-07\n",
      "Epoch 190/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2052e-07 - mae: 1.6926e-04 - mse: 1.2052e-07 - val_loss: 8.4110e-07 - val_mae: 2.4519e-04 - val_mse: 8.4110e-07\n",
      "Epoch 191/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0229e-07 - mae: 1.9594e-04 - mse: 1.0229e-07 - val_loss: 9.6807e-07 - val_mae: 1.9754e-04 - val_mse: 9.6807e-07\n",
      "Epoch 192/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6607e-08 - mae: 1.5209e-04 - mse: 8.6607e-08 - val_loss: 1.0682e-06 - val_mae: 3.2068e-04 - val_mse: 1.0682e-06\n",
      "Epoch 193/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0079e-07 - mae: 1.9835e-04 - mse: 1.0079e-07 - val_loss: 8.4553e-07 - val_mae: 1.5094e-04 - val_mse: 8.4553e-07\n",
      "Epoch 194/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4070e-08 - mae: 1.7216e-04 - mse: 7.4070e-08 - val_loss: 1.0810e-06 - val_mae: 2.3199e-04 - val_mse: 1.0810e-06\n",
      "Epoch 195/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6809e-08 - mae: 1.5602e-04 - mse: 6.6809e-08 - val_loss: 9.0100e-07 - val_mae: 2.8341e-04 - val_mse: 9.0100e-07\n",
      "Epoch 196/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0807e-08 - mae: 1.9007e-04 - mse: 8.0807e-08 - val_loss: 8.7520e-07 - val_mae: 1.7303e-04 - val_mse: 8.7520e-07\n",
      "Epoch 197/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9979e-08 - mae: 1.8404e-04 - mse: 6.9979e-08 - val_loss: 8.0763e-07 - val_mae: 1.4572e-04 - val_mse: 8.0763e-07\n",
      "Epoch 198/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3548e-08 - mae: 1.3952e-04 - mse: 5.3548e-08 - val_loss: 8.5825e-07 - val_mae: 1.5000e-04 - val_mse: 8.5825e-07\n",
      "Epoch 199/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4053e-08 - mae: 1.5460e-04 - mse: 7.4053e-08 - val_loss: 9.3834e-07 - val_mae: 1.8883e-04 - val_mse: 9.3834e-07\n",
      "Epoch 200/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0216e-08 - mae: 1.4813e-04 - mse: 7.0216e-08 - val_loss: 9.9889e-07 - val_mae: 2.2796e-04 - val_mse: 9.9889e-07\n",
      "Epoch 201/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8486e-08 - mae: 1.3642e-04 - mse: 5.8486e-08 - val_loss: 9.0758e-07 - val_mae: 3.1448e-04 - val_mse: 9.0758e-07\n",
      "Epoch 202/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2350e-07 - mae: 2.7178e-04 - mse: 1.2350e-07 - val_loss: 8.4445e-07 - val_mae: 1.7800e-04 - val_mse: 8.4445e-07\n",
      "Epoch 203/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1619e-07 - mae: 2.4572e-04 - mse: 1.1619e-07 - val_loss: 8.9562e-07 - val_mae: 1.5695e-04 - val_mse: 8.9562e-07\n",
      "Epoch 204/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7454e-08 - mae: 1.8855e-04 - mse: 8.7454e-08 - val_loss: 8.9331e-07 - val_mae: 2.0450e-04 - val_mse: 8.9331e-07\n",
      "Epoch 205/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1073e-08 - mae: 1.8401e-04 - mse: 9.1073e-08 - val_loss: 8.7555e-07 - val_mae: 2.7210e-04 - val_mse: 8.7555e-07\n",
      "Epoch 206/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4879e-08 - mae: 1.9078e-04 - mse: 9.4879e-08 - val_loss: 9.5305e-07 - val_mae: 1.6995e-04 - val_mse: 9.5305e-07\n",
      "Epoch 207/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1919e-08 - mae: 1.4295e-04 - mse: 6.1919e-08 - val_loss: 8.9457e-07 - val_mae: 2.2144e-04 - val_mse: 8.9457e-07\n",
      "Epoch 208/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2450e-07 - mae: 2.5478e-04 - mse: 1.2450e-07 - val_loss: 8.6159e-07 - val_mae: 1.9325e-04 - val_mse: 8.6159e-07\n",
      "Epoch 209/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3737e-08 - mae: 1.9934e-04 - mse: 9.3737e-08 - val_loss: 9.8920e-07 - val_mae: 2.7290e-04 - val_mse: 9.8920e-07\n",
      "Epoch 210/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6019e-08 - mae: 1.5784e-04 - mse: 6.6019e-08 - val_loss: 1.0295e-06 - val_mae: 1.9855e-04 - val_mse: 1.0295e-06\n",
      "Epoch 211/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5113e-08 - mae: 1.3561e-04 - mse: 5.5113e-08 - val_loss: 9.7916e-07 - val_mae: 2.8203e-04 - val_mse: 9.7916e-07\n",
      "Epoch 212/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3048e-07 - mae: 2.2950e-04 - mse: 1.3048e-07 - val_loss: 8.5820e-07 - val_mae: 1.4226e-04 - val_mse: 8.5820e-07\n",
      "Epoch 213/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5906e-08 - mae: 1.7594e-04 - mse: 6.5906e-08 - val_loss: 8.8823e-07 - val_mae: 2.2006e-04 - val_mse: 8.8823e-07\n",
      "Epoch 214/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9755e-08 - mae: 1.7233e-04 - mse: 7.9755e-08 - val_loss: 9.0096e-07 - val_mae: 2.3529e-04 - val_mse: 9.0096e-07\n",
      "Epoch 215/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6394e-07 - mae: 2.5638e-04 - mse: 1.6394e-07 - val_loss: 8.1125e-07 - val_mae: 1.4128e-04 - val_mse: 8.1125e-07\n",
      "Epoch 216/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1335e-07 - mae: 1.8225e-04 - mse: 1.1335e-07 - val_loss: 8.3208e-07 - val_mae: 1.7356e-04 - val_mse: 8.3208e-07\n",
      "Epoch 217/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3380e-08 - mae: 1.7257e-04 - mse: 9.3380e-08 - val_loss: 8.7720e-07 - val_mae: 2.8411e-04 - val_mse: 8.7720e-07\n",
      "Epoch 218/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0623e-08 - mae: 1.7223e-04 - mse: 7.0623e-08 - val_loss: 1.0719e-06 - val_mae: 2.1864e-04 - val_mse: 1.0719e-06\n",
      "Epoch 219/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9450e-08 - mae: 1.4391e-04 - mse: 5.9450e-08 - val_loss: 8.8026e-07 - val_mae: 2.5170e-04 - val_mse: 8.8026e-07\n",
      "Epoch 220/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4130e-08 - mae: 1.8169e-04 - mse: 7.4130e-08 - val_loss: 8.3286e-07 - val_mae: 1.6028e-04 - val_mse: 8.3286e-07\n",
      "Epoch 221/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0128e-07 - mae: 2.0752e-04 - mse: 1.0128e-07 - val_loss: 9.5779e-07 - val_mae: 1.5618e-04 - val_mse: 9.5779e-07\n",
      "Epoch 222/500\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6501e-08 - mae: 1.3485e-04 - mse: 5.6501e-08 - val_loss: 9.3669e-07 - val_mae: 1.9374e-04 - val_mse: 9.3669e-07\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Train the Model ---\n",
    "start_time = time.time()\n",
    "print(\"\\nTraining the model...\")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
    "history = model.fit(x_train_scaled, y_train, epochs=500, validation_data=(x_val_scaled, y_val),\n",
    "                    batch_size=32, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d3314649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "\n",
      "Training time: 74.34 seconds.\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(F\"\\nTraining complete.\")\n",
    "print(F\"\\nTraining time: {training_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "14c1ad7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the Model on the test set...\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Evaluate the Model ---\n",
    "print(F\"\\nEvaluating the Model on the test set...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b4d3bf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the unseen test data\n",
    "y_pred = model.predict(x_test_scaled).flatten() # flatten converts a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b00ea2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "print(x_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cd47a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics.\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f7b7ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9369\n",
      "Root Mean Squared Error (RMSE): 0.0002\n",
      "Mean Absolute Error (MAE): 0.0001\n"
     ]
    }
   ],
   "source": [
    "print(F\"R2 Score: {r2:.4f}\")\n",
    "print(F\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(F\"Mean Absolute Error (MAE): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de8d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
